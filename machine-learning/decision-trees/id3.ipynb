{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ID3 Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Условие\n",
    "* Реализирайте алгоритъма за класификационно дърво ID3\n",
    "* Използвайте ***кросвалидация*** за изчисляване на точността на модела върху обучаващото множество. \n",
    "\n",
    "* За избягване на ***overfitting*** използвайте константа **K** -- минимален брой на обучаващи примери в множеството. \n",
    "\n",
    "? друг подход за избягване на ***overfittting*** + сравняване на резултата?  \n",
    "? bonus: ***Random Forest*** ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ucimlrepo import fetch_ucirepo, dotdict\n",
    "from typing import Dict, List, Set, Tuple\n",
    "from dataclasses import dataclass, field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch dataset \n",
    "\n",
    "breast_cancer: dotdict = fetch_ucirepo(id=14)\n",
    "\n",
    "X: pd.core.frame.DataFrame = breast_cancer.data.features \n",
    "y: pd.core.frame.DataFrame = breast_cancer.data.targets\n",
    "\n",
    "values: List[str] = [X[name].unique() for idx, name in enumerate(X.columns)]\n",
    "attributes: List[bool] = [False for _ in X.columns] \n",
    "\n",
    "\n",
    "X: np.ndarray = X.values\n",
    "y: np.ndarray = y.values\n",
    "pos_target: str = \"recurrence-events\"\n",
    "\n",
    "# print(attributes_left)\n",
    "# print(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Split = Dict[str, \"Data\"]\n",
    "\n",
    "class Data:\n",
    "    def __init__(self, \n",
    "                 y_train,\n",
    "                 feature: int = -1, \n",
    "                 feature_val: str=None, \n",
    "                 data: List[int] = None):\n",
    "        self.num_pos: int = 0\n",
    "        self.feature: int = feature\n",
    "        self.feature_val: str = feature_val\n",
    "        self.data: List[int] = data if data else []\n",
    "        self._count_pos(y_train)\n",
    "\n",
    "    def _count_pos(self, y_train: np.ndarray) -> None:\n",
    "        for idx in self.data:\n",
    "            if y_train[idx] == pos_target:\n",
    "                self.num_pos += 1\n",
    "    @property\n",
    "    def prop_predict(self) -> bool:\n",
    "        return self.prop_pos > 0.5\n",
    "\n",
    "    @property\n",
    "    def prop_pos(self) -> float:\n",
    "        return self.num_pos / len(self.data)\n",
    "    @property\n",
    "    def zero_entropy(self) -> bool:\n",
    "        return self.num_pos == len(self) or self.num_pos == 0 \n",
    "    \n",
    "    @property\n",
    "    def full_entropy(self) -> bool:\n",
    "        return self.num_pos == (len(self) - self.num_pos) \n",
    "    \n",
    "    @property\n",
    "    def entropy(self) -> float:\n",
    "        if self.zero_entropy:\n",
    "            return 0\n",
    "\n",
    "        num_neg: int = (len(self) - self.num_pos) \n",
    "        prop_neg: float = num_neg / len(self)\n",
    "\n",
    "        return -self.num_pos * math.log(self.prop_pos) - num_neg * math.log(prop_neg)\n",
    "\n",
    "    @property\n",
    "    def gini(self) -> float:\n",
    "        pass\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data)\n",
    "\n",
    "    def insert_idx(self, idx: int, \n",
    "                   y_train: np.ndarray) -> None:\n",
    "        self.data.append(idx)\n",
    "        if y_train[idx] == pos_target:\n",
    "            self.num_pos += 1\n",
    "\n",
    "    def split_on_attribute(self, feature: int, \n",
    "                           X_train: np.ndarray, \n",
    "                           y_train: np.ndarray) -> Split:\n",
    "        spl: Split = {val: Data(feature=feature, \n",
    "                                feature_val=val, \n",
    "                                y_train=y_train) for val in values[feature]}\n",
    "        \n",
    "        for idx in self.data:\n",
    "            val: str = X_train[idx][feature]\n",
    "            spl[val].insert_idx(idx, y_train)\n",
    "\n",
    "        return spl\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return repr(self.data)\n",
    "\n",
    "dt = Data(data=list(range(len(X))), y_train=y)\n",
    "spl: Split = dt.split_on_attribute(0, X, y_train=y)\n",
    "\n",
    "# print(type(spl))\n",
    "# print(dt.data)\n",
    "# print(dt.num_pos)\n",
    "# print(dt.prop_pos)\n",
    "# print(dt.entropy)\n",
    "# for key, value in spl.items():\n",
    "#     print(f\"{key}: {value.entropy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "\n",
    "    def __init__(self, X_train, y_train, data: Data=Data) -> None:\n",
    "        self.data: Data = data\n",
    "        self.children: Dict[str, Node] = {}\n",
    "        self.attribute: int = -1\n",
    "        self._build_children(X_train, y_train)\n",
    "    \n",
    "    def information_gain(self, spl: Split) -> float:\n",
    "        sum_term: float = sum([(len(val) / len(self.data)) * val.entropy for _, val in spl.items()])\n",
    "        return self.data.entropy - sum_term\n",
    "\n",
    "    def get_best_split(self, X_train: np.ndarray, y_train: np.ndarray) -> Tuple[int, Split]:\n",
    "        best: Split = {}\n",
    "        best_score: float = float(\"-inf\")\n",
    "        feature: int = -1\n",
    "        for i in range(len(attributes)):\n",
    "            if not attributes[i]:\n",
    "                spl: Split = self.data.split_on_attribute(i, X_train, y_train)\n",
    "                ig: float = self.information_gain(spl)\n",
    "                if ig > best_score:\n",
    "                    best_score = ig\n",
    "                    best = spl\n",
    "                    feature = i\n",
    "        return feature, best\n",
    "\n",
    "    @property\n",
    "    def leaf(self) -> bool:\n",
    "        return False if self.children else True\n",
    "\n",
    "    def predict(self, X: np.ndarray) -> bool:\n",
    "        if not self.children:\n",
    "            return self.data.prop_predict\n",
    "        \n",
    "        for val, child in self.children.items():\n",
    "            if X[self.attribute] == val:\n",
    "                if child.leaf and child.data.full_entropy:\n",
    "                    return self.data.prop_predict\n",
    "                return child.predict(X)\n",
    "\n",
    "\n",
    "\n",
    "    def _build_children(self, X_train: np.ndarray, y_train: np.ndarray) -> None:\n",
    "        # print(sum(attributes) == len(attributes), sum(attributes) == len(attributes))\n",
    "        if self.data.zero_entropy or sum(attributes) == len(attributes):\n",
    "            # print(\"42\")\n",
    "            return\n",
    "        feature, best_split = self.get_best_split(X_train, y_train)\n",
    "        attributes[feature] = True\n",
    "        self.attribute = feature\n",
    "    \n",
    "        for val, data in best_split.items():\n",
    "            self.children[val] = Node(data=data, X_train=X_train, y_train=y_train)\n",
    "\n",
    "\n",
    "attributes = [False for _ in attributes]\n",
    "n = Node(X_train=X[100:], y_train=y[100:], data=Data(data=list(range(len(X[100:]))), y_train=y[100:]))\n",
    "\n",
    "# for i in range(len(X)):\n",
    "\n",
    "\n",
    "# print(\"age\", n.information_gain(spl))\n",
    "# print(n.get_best_split(X_train=X_train))\n",
    "# print(n.children)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6567733990147783"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import  train_test_split, KFold\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)\n",
    "\n",
    "# attributes = [False for _ in attributes]\n",
    "# n = Node(X_train, y_train, data=Data(data=list(range(len(X_train))), y_train=y_train))\n",
    "\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "# mistakes = 0\n",
    "# for i in range(len(X[:100])):\n",
    "#     act = y[i] == pos_target\n",
    "#     if n.predict(X[i]) != act:\n",
    "#         mistakes += 1\n",
    "\n",
    "# print(1 - mistakes / len(X))\n",
    "\n",
    "accs = []\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    attributes = [False for _ in attributes]\n",
    "    n = Node(X_train=X_train, y_train=y_train, data=Data(data=list(range(len(X_train))), y_train=y_train))\n",
    "\n",
    "    mistakes = 0\n",
    "    for i in range(len(X_test)):\n",
    "        temp = y_test[i] == pos_target\n",
    "        if temp != n.predict(X_test[i]):\n",
    "            mistakes += 1\n",
    "    accs.append(1 - mistakes / len(X_test)) \n",
    "\n",
    "sum(accs) / len(accs)\n",
    "\n",
    "\n",
    "# # act = y == pos_target\n",
    "# mistakes = 0\n",
    "# for i in range(len(X[:30])):\n",
    "#     if(n.predict(X[i]) != act[i]):\n",
    "#         mistakes += 1\n",
    "# print(1 - mistakes / len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
